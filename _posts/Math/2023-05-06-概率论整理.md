---
layout: post
title: 概率论公式整理
subtitle: 
categories: markdown Math
tags: [Math]
math: true
---

## 概率

频率 $f_n(A)=\frac{k}{n}$
1. $ 0 \leq f_n(A) \leq 1$
2. 对于必然事件$\Omega$ $f_n(\Omega)=1$
3. 若事件不相容 $A \cap B = \emptyset$ 则 $f_n(A \cup B) = f_n(A) + f_n(B)$

若事件两两不相容

$$
f_n(\bigcup_{i=1}^n A_i) = \sum_{i=1}^n f_n(A_i)
$$

有限可加性：事件$A_i$两两不相容

$$
P(\bigcup_{i=1}^{n} A_i) = \sum_{i=1}^{n} P(A_i)
$$

基本运算公式

$$
\begin{align*}
    P(A \cup B) &= P(A) + P(B) - P(A \cap B)\\
    P(A - B) &= P(A) - P(A \cap B)\\
    P( \overline{A} ) &= 1 - P(A)\\
    P(A \cup B \cup C) &= P(A) + P(B) + P(C) - P(A \cap B) - P(A \cap C) - P(B \cap C) + P(A \cap B \cap C)\\
    P(\bigcup_{i=1}^{n} A_i) &= \sum_{i=1}^{n} P(A_i) - \sum_{1 \leq i < j \leq n} P(A_i \cap A_j) + \sum_{1 \leq i < j < k \leq n} P(A_i \cap A_j \cap A_k) + \cdots + (-1)^{n-1} P(A_1 \cap A_2 \cap \cdots \cap A_n)
\end{align*}
$$

## 条件概率

**条件概率**

$$
P(B|A) = \frac{P(AB)}{P(A)}
$$

含义：在事件A发生的条件下，事件B发生的概率
变式

$$
\begin{align*}
P(AB) &= P(A)P(B|A) = P(B)P(A|B)\\
P(AB) &= \frac{P(AB|U)}{P(B|U)}\\
P(ABC) &= P(A)P(B|A)P(C|AB)\\
P(\bigcap_{i=1}^{n} A_i) &= P(A_1)P(A_2|A_1)P(A_3|A_1A_2) \cdots P(A_n|A_1A_2 \cdots A_{n-1})
\end{align*}
$$

**全概率公式**

$$
P(B) = \sum_{i=1}^{n} P(A_i)P(B|A_i)
$$

含义：B的概率等于在所有可能发生的事件$A_i$发生的条件下，B发生的概率的和
**贝叶斯公式（逆概率公式）**

$$
P(A_i|B) = \frac{P(A_i)P(B|A_i)}{\sum_{j=1}^{n} P(A_j)P(B|A_j)} = \frac{P(A_i)P(B|A_i)}{P(B)}
$$

## 独立性

$$
\begin{align*}
P(AB) &= P(A)P(B)\\
P(ABC) &= P(A)P(B)P(C)\\
P(\bigcap_{i=1}^{n} A_i) &= \prod_{i=1}^{n} P(A_i)
\end{align*}
$$

若A,B独立，则

$A \cap B = \emptyset$，
$P(A \cap B) = 0$，
$P(A \cup B) = P(A) + P(B)$, 
$P(B|A) = P(B|\overline{A}) P(B)$

### 伯努利实验
1. 试验只有两个结果：$A$和$\overline{A}$
2. 试验可以重复进行
3. 每次试验结果相互独立

$$
P(A)=p \qquad P(\overline{A})=1-p
$$

k重伯努利实验下A出现k次的概率

$$
P_n(k) = C_n^k p^k (1-p)^{n-k}
$$

## 随机变量
**随机变量**：对于随机试验，对每个样本点赋予一个实数，这个实数就是随机变量
**离散型随机变量**：随机变量只能取有限个或可列个值
**连续型随机变量**：随机变量的取值是一个区间内的任意一个值

**分布函数**
X是一个随机变量，对于任意实数x，函数

$$
F(x) = P\{X \leq x\}
$$

称为X的分布函数

1. $F(x)$非严格单调递增
2. $0 \leq F(x) \leq 1$
3. $\lim_{x \to -\infty} F(x) = 0$，$\lim_{x \to +\infty} F(x) = 1$
4. $F(x)$右连续（左闭右开）

### 离散型随机变量
概率分布、分布律

$$
P\{X=x_i\} = p_i \qquad i=1,2,\cdots
$$

1. $p_i \geq 0$
2. $\sum_{i=1}^{\infty} p_i = 1$

#### 二项分布
二项分布是n重伯努利实验中成功次数的离散型概率分布

$$
P\{X=k\} = C_n^k p^k (1-p)^{n-k} \qquad k=0,1,2,\cdots,n
$$

#### 泊松分布
泊松分布是二项分布的极限情况，当n很大，p很小时，二项分布近似于泊松分布

$$
P\{X=k\} = \lim_{n \to \infty} C_n^k p^k (1-p)^{n-k} = \frac{\lambda^k}{k!} e^{-\lambda} \qquad k=0,1,2,\cdots
$$

泊松分布的期望和方差

$$
E(X) = \lambda \qquad D(X) = \lambda
$$

### 连续型随机变量
概率密度函数

$$
F(x) = \int_{-\infty}^{x} f(t) dt
$$

$$
\begin{align*}
f(x) &\geq 0\\
\int_{-\infty}^{+\infty} f(x) dx &= 1\\
P\{a \leq X \leq b\} &= \int_{a}^{b} f(x) dx\\
F^{'}(x) &= f(x) \qquad 如果f(x)在x处连续
\end{align*}
$$

#### 均匀分布

$$
f(x) = \begin{cases}
\frac{1}{b-a} & a \leq x \leq b\\
0 & 其他
\end{cases}
$$

$$
F(x) = \begin{cases}
0 & x < a\\
\frac{x-a}{b-a} & a \leq x \leq b\\
1 & x > b
\end{cases}
$$

均匀分布的期望和方差

$$
E(X) = \frac{a+b}{2} \qquad D(X) = \frac{(b-a)^2}{12}
$$

#### 指数分布

$$
f(x) = \begin{cases}
\lambda e^{-\lambda x} & x \geq 0\\
0 & x < 0
\end{cases}
$$

$$
F(x) = \begin{cases}
1-e^{-\lambda x} & x \geq 0\\
0 & x < 0
\end{cases}
$$

无记忆性

$$
P\{X > s+t | X > s\} = P\{X > t\}
$$

指数分布的期望和方差

$$
E(X) = \frac{1}{\lambda} \qquad D(X) = \frac{1}{\lambda^2}
$$

#### 正态分布
！此公式重要

$$
f(x) = \frac{1}{\sqrt{2\pi}\sigma} e^{-\frac{(x-\mu)^2}{2\sigma^2}} \qquad 
\frac{1}{\sqrt{2\pi}\sigma} \exp({-\frac{(x-\mu)^2}{2\sigma^2}})
$$

正态分布的期望和方差

$$
E(X) = \mu \qquad D(X) = \sigma^2
$$

#### 随机变量函数的分布
设X是一个随机变量，Y是随机变量X的函数，即$Y = g(X)$，则Y是一个随机变量，其分布函数为

$$
\begin{align*}
F_Y(y) &= P\{Y \leq y\}\\
&= P\{g(X) \leq y\}\\
&= P\{X \leq g^{-1}(y)\}\\
&= F_X(g^{-1}(y))\\
\end{align*}
$$

$$
f_Y(y) = \frac{dF_Y(y)}{dy} = f_X(g^{-1}(y)) |\frac{d}{dy}g^{-1}(y)|
$$

## 随机向量
**随机向量**：设$(X_1,X_2,\cdots,X_n)$是n个随机变量，它们构成的向量$(X_1,X_2,\cdots,X_n)$称为n维随机向量

**二维随机向量**：设$(X,Y)$是二维随机变量，对于任意实数$x,y$，函数

$$
F(x,y) = P\{X \leq x, Y \leq y\}
$$

称为二维随机变量$(X,Y)$的分布函数

1. $\frac{\partial F}{\partial x} \geq 0 \quad \frac{\partial F}{\partial y} \geq 0$
2. $0 \leq F(x,y) \leq 1$
3. $F(-\infty,y) = F(x,-\infty) = 0$
4. $F(+\infty,+\infty) = 1$
5. $F(x,y)$关于x和y都是右连续的
6. $P\{a_1 < X \leq b_1, a_2 < Y \leq b_2\} = F(b_1,b_2) - F(a_1,b_2) - F(b_1,a_2) + F(a_1,a_2)$

**二维离散型随机变量**：设$(X,Y)$是二维随机变量，如果存在一列非负常数$p_{ij}(i,j=1,2,\cdots)$，使得

$$
P\{X=x_i,Y=y_j\} = p_{ij} \qquad i,j=1,2,\cdots
$$

则称$(X,Y)$为二维离散型随机变量，其中$p_{ij}$满足

$$
\sum_{i=1}^{\infty} \sum_{j=1}^{\infty} p_{ij} = 1
$$

**二维连续型随机变量**：设$(X,Y)$是二维随机变量，如果存在非负常数$f(x,y)$，使得对于任意实数$x,y$，有

$$
P\{(X,Y) \in D\} = \iint_D f(x,y)dxdy
$$

### 分布律

二维离散型随机变量的分布律

$$
\begin{align*}
P\{X=x_i,Y=y_j\} &= p_{ij} \qquad i,j=1,2,\cdots\\
\end{align*}
$$

二维连续型随机变量的概率密度

$$
\begin{align*}
f(x,y) &\geq 0\\
\iint_{-\infty}^{+\infty} f(x,y)dxdy &= 1\\
\frac{\partial^2 F(x,y)}{\partial x \partial y} &= f(x,y) \quad 若f(x,y)在点(x,y)连续\\
P\{(X,Y) \in D\} &= \iint_D f(x,y)dxdy
\end{align*}
$$

### 边缘分布律
二维离散型随机变量的边缘分布律

$$
\begin{align*}
P\{X=x_i\} &= \sum_{j=1}^{\infty} P\{X=x_i,Y=y_j\} = \sum_{j=1}^{\infty} p_{ij} \qquad i=1,2,\cdots\\
P\{Y=y_j\} &= \sum_{i=1}^{\infty} P\{X=x_i,Y=y_j\} = \sum_{i=1}^{\infty} p_{ij} \qquad j=1,2,\cdots
\end{align*}
$$

二维连续型随机变量的边缘概率密度

$$
\begin{align*}
f_X(x) &= \int_{-\infty}^{+\infty} f(x,y)dy\\
f_Y(y) &= \int_{-\infty}^{+\infty} f(x,y)dx
\end{align*}
$$

二维连续型随机变量的边缘分布律

$$
\begin{align*}
F_X(x) &= P\{X \leq x\} = P\{X \leq x, -\infty < Y < +\infty\} = \int_{-\infty}^{x} \int_{-\infty}^{+\infty} f(u,y)dydu = \int_{-\infty}^{x} f_X(u)du\\
F_Y(y) &= P\{Y \leq y\} = P\{Y \leq y, -\infty < X < +\infty\} = \int_{-\infty}^{y} \int_{-\infty}^{+\infty} f(x,v)dxdv = \int_{-\infty}^{y} f_Y(v)dv
\end{align*}
$$

### 条件分布
条件分布

$$
\begin{align*}
F_{X|Y}(x|y) &= P\{X \leq x|Y=y\} = \frac{P\{X \leq x, Y=y\}}{P\{Y=y\}} = \frac{\int_{-\infty}^{x} f(u,y)du}{f_Y(y)}\\
f_{X|Y}(x|y) &= \frac{f(x,y)}{f_Y(y)}\\
F_{Y|X}(y|x) &= \frac{f(x,y)}{f_X(x)}\\
f_{Y|X}(y|x) &= \frac{f(x,y)}{f_X(x)}
\end{align*}
$$

二维离散型随机变量的条件分布律

$$
\begin{align*}
P\{X=x_i|Y=y_j\} &= \frac{P\{X=x_i,Y=y_j\}}{P\{Y=y_j\}} = \frac{p_{ij}}{\sum_{k=1}^{\infty} p_{kj}} \qquad i=1,2,\cdots\\
P\{Y=y_j|X=x_i\} &= \frac{P\{X=x_i,Y=y_j\}}{P\{X=x_i\}} = \frac{p_{ij}}{\sum_{k=1}^{\infty} p_{ik}} \qquad j=1,2,\cdots
\end{align*}
$$

### 二维随机变量函数的分布
设$(X,Y)$是二维随机变量，$Z=\varphi(X,Y)$是由$(X,Y)$所确定的随机变量，如果对于任意实数$z$，有

$$
P\{Z \leq z\} = P\{\varphi(X,Y) \leq z\} = P\{(X,Y) \in D_z\} = \iint_{D_z} f(x,y)dxdy
$$

#### 1. $Z = X+Y$

$$
\begin{align*}
    F_Z(z) = P\{X+Y \leq z\} 
    &= \iint_{x+y \leq z} f(x,y)dxdy\\
    &= \int_{-\infty}^{+\infty} \int_{-\infty}^{z-y} f(x,y)dxdy\\
\end{align*}
$$

令$u=x+y,v=y$，则 $x=u-v,y=v$，
$$
D_z = \{(u,v) | u \geq v, v \leq z \}
$$

$$
\begin{align*}
    F_Z(z) &= \int_{-\infty}^{+\infty} \int_{-\infty}^{z} f(u-v,v)du dv\\
    &= \int_{-\infty}^{z} \int_{-\infty}^{+\infty} f(u-v,v)dv du\\
    &= \int_{-\infty}^{z} f_Z(u)du
\end{align*}
$$

由对称性可得

$$
\begin{align*}
f_Z(z) &= \int_{-\infty}^{+\infty} f(x-y,y)dy\\
&= \int_{-\infty}^{+\infty} f(x,z-x)dx\\
\end{align*}
$$

当$f(x,y) = f_X(x)f_Y(y)$时，$X,Y$相互独立，得到卷积公式

$$
\begin{align*}
f_Z(z) = f_X*f_Y&= \int_{-\infty}^{+\infty} f_X(x)f_Y(z-x)dx\\
&= \int_{-\infty}^{+\infty} f_X(z-y)f_Y(y)dy\\
\end{align*}
$$

#### 2. $Z = XY$

$$
\begin{align*}
    F_Z(z) = P\{XY \leq z\} 
    &= \iint_{xy \leq z} f(x,y)dxdy\\
    &= \int_{-\infty}^{+\infty} \int_{-\infty}^{z/x} f(x,y)dydx\\
\end{align*}
$$

#### 3. $Z = \frac{X}{Y}$

$$
\begin{align*}
    F_Z(z) = P\{\frac{X}{Y} \leq z\} 
    &= \iint_{\frac{x}{y} \leq z} f(x,y)dxdy\\
    &= \int_{-\infty}^{+\infty} \int_{-\infty}^{xz} f(x,y)dydx\\
\end{align*}
$$

令$u=y \qquad v=\frac{x}{y}$，则 $x=uv,y=u$，
$$
D_z = \{(u,v) | u \geq 0, v \leq z\}
$$

$$
J = \begin{vmatrix}
    \frac{\partial x}{\partial u} & \frac{\partial x}{\partial v}\\
    \frac{\partial y}{\partial u} & \frac{\partial y}{\partial v}\\
\end{vmatrix} = \begin{vmatrix}
    v & u\\
    0 & 1\\
\end{vmatrix} = -u
$$

$$
\begin{align*}
    F_Z(z) &= \int_{-\infty}^{+\infty} \int_{-\infty}^{z} f(uv,u)|J|dv du\\
    &= \int_{-\infty}^{z} \int_{0}^{+\infty} f(uv,u)|u|dv du\\
    &= \int_{-\infty}^{z} f_Z(u)du
\end{align*}
$$

$$
\begin{align*}
f_Z(z) &= \int_{-\infty}^{+\infty} f(zu,u)|u|du\\
\end{align*}
$$

当$f(x,y) = f_X(x)f_Y(y)$时，$X,Y$相互独立

$$
f_Z(z) = \int_{-\infty}^{+\infty} f_X(zu)f_Y(u)|u|du
$$

#### 4. $M = \max\{X,Y\}$

X,Y相互独立

$$
\begin{align*}
    F_M(m) &= P\{\max\{X,Y\} \leq m\}\\
    &= P\{X \leq m\}P\{Y \leq m\}\\
    &= F_X(m)F_Y(m)
\end{align*}
$$

#### 5. $N = \min\{X,Y\}$

$$
\begin{align*}
    F_N(n) &= P\{\min\{X,Y\} \leq n\}\\
    &= 1 - P\{\min\{X,Y\} > n\}\\
    &= 1 - P\{X > n\}P\{Y > n\}\\
    &= 1 - (1-F_X(n))(1-F_Y(n))\\
\end{align*}
$$

## 数字特征
### 期望
离散型随机变量的期望

$$
E(X) = \sum_{i=1}^{n} x_i p_i
$$

连续型随机变量的期望

$$
E(X) = \int_{-\infty}^{+\infty} xf(x)dx
$$

性质

$$
    E(Z) = E(g(X)) = \sum_{i=1}^{n} g(x_i)p_i \qquad E(Z) = E(g(X)) = \int_{-\infty}^{+\infty} g(x)f(x)dx\\
$$

$$
E(aX+bY) = aE(X) + bE(Y)\\
$$

若X,Y相互独立，则

$$
E(XY) = E(X)E(Y)
$$

### 方差
离散型随机变量的方差

$$
D(X) = \sum_{i=1}^{n} (x_i - E(X))^2 p_i = E(X^2) - [E(X)]^2
$$

连续型随机变量的方差

$$
D(X) = \int_{-\infty}^{+\infty} (x - E(X))^2 f(x)dx = E(X^2) - [E(X)]^2
$$

性质

$$
\begin{align}
    D(aX+b) &= a^2D(X)\\
    D(X \pm Y) &= D(X) + D(Y) \pm 2Cov(X,Y)\\
    &= D(X) + D(Y) \qquad X,Y相互独立\\
    D(X) &< E[(X-c)^2] \qquad c \neq E(X)\\
    D(X) &= 0 \Leftrightarrow X = c \qquad c为常数
\end{align}
$$

### 协方差

$$
Cov(X,Y) = E[(X-E(X))(Y-E(Y))] = E(XY) - E(X)E(Y)
$$

性质

$$
\begin{align*}
    Cov(X,Y) &= Cov(Y,X)\\
    Cov(aX+bY,Z) &= aCov(X,Z) + bCov(Y,Z)\\
    Cov(X,Y) &= 0 \Leftarrow X,Y相互独立\\
\end{align*}
$$

### 相关系数

$$
\rho_{XY} = \frac{Cov(X,Y)}{\sqrt{D(X)D(Y)}} = \frac{E(XY) - E(X)E(Y)}{\sqrt{D(X)D(Y)}}
$$

性质

$$
\begin{align*}
    \rho_{XY} &= \rho_{YX}\\
    |\rho_{XY}| &\leq 1\\
    |\rho_{XY}| &= 1 \Leftrightarrow P\{Y=aX+b\} = 1\\
    \rho_{XY} &= 0 \Leftrightarrow X,Y相互独立
\end{align*}
$$

### 常用分布性质表
|—|
|:---:|

|分布|分布律（概率密度）|期望|方差|范围|
|:---:|:---:|:---:|:---:|:---:|
|0-1分布|$p\{X=1\} = p,p\{X=0\} = q$|$p$|$pq$|$0<p<1,q=1-p$|
|二项分布$X\sim b(n,p)$|$p\{X=k\} = C_n^kp^kq^{n-k}$|$np$|$npq$|$0<p<1,q=1-p,n \in N^*$|
|泊松分布$X\sim P(\lambda)$|$p\{X=k\} = \frac{\lambda^k}{k!}e^{-\lambda}$|$\lambda$|$\lambda$|$\lambda>0$|
|均匀分布$X\sim U(a,b)$|$f(x) = \begin{cases}\frac{1}{b-a},&a<x<b\newline 0,&其他\end{cases}$|$\frac{a+b}{2}$|$\frac{(b-a)^2}{12}$|$-\infty<a<b<+\infty$|
|指数分布$X\sim E(\lambda)$|$f(x) = \begin{cases}\lambda e^{-\lambda x},&x>0\newline 0,&x\leq 0\end{cases}$|$\frac{1}{\lambda}$|$\frac{1}{\lambda^2}$|$\lambda>0$|
|正态分布$X\sim N(\mu,\sigma^2)$|$f(x) = \frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-\mu)^2}{2\sigma^2}}$|$\mu$|$\sigma^2$|$-\infty<x<+\infty$|

## 大数定理

切比雪夫不等式

$$
P\{|X-E(X)| \geq \varepsilon\} \leq \frac{D(X)}{\varepsilon^2}
$$

$$
P\{|X-E(X)| < \varepsilon\} \geq 1 - \frac{D(X)}{\varepsilon^2}
$$

收敛
设$Y_1,Y_2,\cdots,Y_n,\cdots$是随机变量序列，$a$是常数，如果对于任意的$\varepsilon > 0$，有

$$
\lim_{n \to \infty} P\{|Y_n - a| < \varepsilon\} = 1
$$

则称随机变量序列$Y_1,Y_2,\cdots,Y_n,\cdots$依概率收敛于$a$，记作

$$
Y_n \xrightarrow{P} a \qquad (n \to \infty)
$$

### 切比雪夫大数定理
条件
1. $X_1,X_2,\cdots,X_n,\cdots$相互独立
2. $\forall i \quad D(X_i) = \sigma^2 < l$  $l$是常数
   
$$
P\{ |\frac{1}{n}\sum_{i=1}^{n}X_i - E(X)| \geq \varepsilon \} \leq \frac{D(X)}{n\varepsilon^2}
$$

即

$$
avg(X_i) \xrightarrow{P} avg(E(X_i)) \qquad (n \to \infty)
$$

推论
当
1. $X_1,X_2,\cdots,X_n,\cdots$相互独立
2. $\forall i \quad E(X_i) = \mu \quad D(X_i) = \sigma^2$
   
$$
\lim_{n \to \infty} P\{|\frac{1}{n}\sum_{i=1}^{n}X_i - \mu| < \varepsilon\} = 1
$$

即

$$
avg(X_i) \xrightarrow{P} \mu
$$

### 伯努利大数定理
$n_A$是$n$次重实验中时间A发生的次数，A发生的概率为$p$

$$
\lim_{n \to \infty} P\{|\frac{n_A}{n} - p| < \varepsilon\} = 1
$$

即

$$
\frac{n_A}{n} \xrightarrow{P} p
$$

### 辛钦大数定理

条件
1. $X_1,X_2,\cdots,X_n,\cdots$相互独立
2. $X_i$服从同一分布 $E(X_i) = \mu$
   
$$
\lim_{n \to \infty} P\{|\frac{1}{n}\sum_{i=1}^{n}X_i - \mu| < \varepsilon\} = 1
$$

即

$$
avg(X_i) \xrightarrow{P} \mu
$$
## 中心极限定理

### 林德贝格-勒维/独立同分布中心极限定理
条件
1. $X_1,X_2,\cdots,X_n,\cdots$相互独立
2. $X_i$服从同一分布，$E(X_i) = \mu \quad D(X_i) = \sigma^2$

$$
\lim_{n \to \infty} P\{\frac{\sum_{i=1}^{n}X_i - n\mu}{\sigma\sqrt{n}} \leq x\} = \frac{1}{\sqrt{2\pi}}\int_{-\infty}^{x}e^{-\frac{t^2}{2}}dt
$$

即当$n$充分大时

$$
\begin{align*}
\frac{\sum_{i=1}^{n}X_i - n\mu}{\sigma\sqrt{n}} \sim N(0,1)\\
\sum_{i=1}^{n}X_i \sim N(n\mu,n\sigma^2)
\end{align*}
$$

### 李雅普诺夫/独立不同分布中心极限定理
条件
1. $X_1,X_2,\cdots,X_n,\cdots$相互独立
2. $E(x_i) = \mu_i \quad D(X_i) = \sigma_i^2 \neq 0$

存在正数$\delta$使得当$n \to \infty$时

$$
\frac{1}{\sum_{i=1}^{n}\sigma_i^{2+\delta}}\sum_{i=1}^{n}E(|X_i - \mu_i|^{2+\delta}) \to 0
$$

则随机变量

$$
Z_n = \frac{\sum_{i=1}^{n}X_i - \sum_{i=1}^{n}\mu_i}{\sqrt{D(\sum_{i=1}^{n}X_i)}} = \frac{\sum_{i=1}^{n}X_i - \sum_{i=1}^{n}\mu_i}{\sum_{i=1}^{n}\sigma_i}
$$

的分布函数$F_n(x)$对于任意$x$满足

$$
\lim_{n \to \infty} F_n(x) = \Phi(x)
$$

即当$n$充分大时

$$
\begin{align*}
Z_n &\sim N(0,1)\\
\sum_{i=1}^{n}X_i &\sim N(\sum_{i=1}^{n}\mu_i,\sum_{i=1}^{n}\sigma_i^2)
\end{align*}
$$

### 拉普拉斯/局部极限定理 、棣莫弗-拉普拉斯/积分极限定理
条件
1. 随机变量$X \sim B(n,p)$
2. $n$充分大

注：$E(X) = np\quad D(X) = npq \quad \sigma = \sqrt{npq}$
拉普拉斯定理

$$
P\{X=k\} \approx \frac{1}{\sqrt{2\pi npq}}e^{-\frac{(k-np)^2}{2npq}} = \frac{1}{\sqrt{npq}} \varphi(\frac{k-np}{\sqrt{npq}})
$$

棣莫弗-拉普拉斯

$$
\lim_{n \to \infty} P\{a \leq \frac{X-np}{\sqrt{npq}} \leq b\} = \Phi(b) - \Phi(a)
$$

即

$$\begin{align*}
\frac{X-np}{\sqrt{npq}} &\sim N(0,1)\\
X &\sim N(np,npq)
\end{align*}
$$


## 参数估计

### 点估计
#### 矩估计

**矩**：$k$阶原点矩$E(X^k)$，$k$阶中心矩$E(X-\mu)^k$

1. $E(X) = \mu$
2. $E(X^2) = \mu^2 + \sigma^2$
3. $E(X^3) = \mu^3 + 3\mu\sigma^2$
4. $E(X^4) = \mu^4 + 6\mu^2\sigma^2 + 3\sigma^4$

#### 最大似然估计(maximum likelihood estimation)

**likelihood function**
likelihood function是一个关于参数$\theta$的函数，表示在给定参数$\theta$的条件下，样本观测值出现的概率，记为$L(\theta)$
**maximum likelihood**
最大似然估计是指在所有可能的参数值中，使得观测值出现的概率最大的那个参数值，记为$\hat{\theta}$

随机变量，$X$在参数 $\theta$ 西的概率分布为 $P\{X=x_i\} = f(x_i;\theta) \quad i=1,2,\cdots,n$ ，则样本$X_1,X_2,\cdots,X_n$的联合概率分布为

$$
P\{X_1=x_{i1},X_2=x_{i2},\cdots,X_n=x_{in}\} = \prod_{i=1}^{n}f(x_{i};\theta)
$$

其中$n_i$表示样本中$X$取值为$x_i$的个数，$n = \sum_{i=1}^{n}n_i$ ，则样本的似然函数为

$$
L(p_1,p_2,\cdots,p_n) = \prod_{i=1}^{n}f(x_{i};\theta)
$$

找到使得似然函数最大的参数值，即为最大似然估计

$$
\hat{\theta} = \arg \max_{\theta} L(\theta)
$$

因为似然函数是连乘，求导不方便，通常对似然函数取对数，即对数似然函数

$$
\ln L(\theta) = \sum_{i=1}^{n}\ln f(x_i;\theta)
$$

$$
\hat{\theta} = \arg \max_{\theta} \ln L(\theta)
$$

**maximum likelihood estimation**

求likelihood function的最大值，即求对likelihood functio的导数为0的点

$$
\frac{\partial \ln L(\theta)}{\partial \theta} = 0
$$

对于k个参数，有k个方程，解方程组得到参数的最大似然估计值

$$
\begin{cases}
\frac{\partial \ln L(\theta)}{\partial \theta_1} = 0\\
\frac{\partial \ln L(\theta)}{\partial \theta_2} = 0\\
\cdots\\
\frac{\partial \ln L(\theta)}{\partial \theta_k} = 0
\end{cases}
$$

### 估计的评价标准

#### 无偏性

**无偏性**：估计量的数学期望等于被估计参数的真实值

$$
E(\hat{\theta}) = \theta
$$

#### 有效性

**有效性**：估计量的方差小于等于其他估计量的方差

$$
D(\hat{\theta}) \leq D(\tilde{\theta})
$$

称$\hat{\theta}$比$\tilde{\theta}$有效

#### 一致性

**一致性**：当样本容量$n$趋于无穷大时，估计量的值趋于被估计参数的真实值

$$
\lim_{n \to \infty} \hat{\theta} = \theta
$$

或

$$
\lim_{n \to \infty} P\{|\hat{\theta} - \theta| < \epsilon\} = 1
$$

### 区间估计

#### 置信区间

**置信区间**：在一定置信水平下，估计参数的区间

设总体$X$的分布为$f(x;\theta)$，$\theta$为待估参数，$X_1,X_2,\cdots,X_n$为来自$X$的样本，$\hat{\theta}$为$\theta$的估计量，$\theta$的置信水平为$1-\alpha$，则称随机区间 $(\hat{\theta}_1,\hat{\theta}_2)$ 为$\theta$的置信水平为$1-\alpha$的置信区间，如果对于任意$\theta$，有

$$
P\{\hat{\theta}_1 < \theta < \hat{\theta}_2\} = 1-\alpha
$$

其中$\hat{\theta}_1,\hat{\theta}_2$为$\theta$的函数，称为置信下限和置信上限

#### 枢轴变量

**枢轴变量**：枢轴变量是样本均值$\bar{X}$和样本方差$S^2$的函数，记为$Q(\bar{X},S^2)$，枢轴变量的分布不依赖于待估参数，即枢轴变量的分布不依赖于$\theta$，则称$Q(\bar{X},S^2)$为$\theta$的枢轴量

#### 枢轴量法

**枢轴量法**：设总体$X$的分布为$f(x;\theta)$，$\theta$为待估参数，$X_1,X_2,\cdots,X_n$为来自$X$的样本，$\hat{\theta}$为$\theta$的估计量，$\theta$的置信水平为$1-\alpha$，$Q(\bar{X},S^2)$为$\theta$的枢轴量，$Q(\bar{X},S^2)$的分布不依赖于$\theta$，则有

$$
P\{a < Q(\bar{X},S^2) < b\} = 1-\alpha
$$

其中$a,b$为常数，由此得到$\theta$的置信水平为$1-\alpha$的置信区间为 $(\hat{\theta}_1,\hat{\theta}_2)$

#### 正态总体的区间估计

设总体$X$的分布为$N(\mu,\sigma^2)$，$\mu$为待估参数，$X_1,X_2,\cdots,X_n$为来自$X$的样本，$\bar{X}$为$\mu$的估计量，$S^2$为$\sigma^2$的估计量，$\mu$的置信水平为$1-\alpha$

##### 1. 对$\mu$的估计
若$\sigma^2$已知，则有置信区间为

$$
(\bar{X} - \frac{\sigma}{\sqrt{n}}z_{\alpha/2},\bar{X} + \frac{\sigma}{\sqrt{n}}z_{\alpha/2})
$$

若$\sigma^2$未知

考虑$S^2 = \frac{1}{n-1}\sum_{i=1}^{n}(X_i - \bar{X})^2$是$\sigma^2$的无偏估计量，则有

$$
T = \frac{\bar{X} - \mu}{S/\sqrt{n}} \sim t(n-1)
$$

则有置信区间为

$$
(\bar{X} - \frac{S}{\sqrt{n}}t_{\alpha/2}(n-1),\bar{X} + \frac{S}{\sqrt{n}}t_{\alpha/2}(n-1))
$$

又因为 $\frac{S}{\sqrt{n}} = \frac{S_0}{\sqrt{n-1}}$ 其中$S_0 = \sqrt{\frac{1}{n-1}\sum_{i=1}^{n}(X_i - \bar{X})^2}$，置信区间可以写做

$$
(\bar{X} - \frac{S_0}{\sqrt{n-1}}t_{\alpha/2}(n-1),\bar{X} + \frac{S_0}{\sqrt{n-1}}t_{\alpha/2}(n-1))
$$

##### 2. 对$\sigma^2$的估计

只考虑$\mu$未知的情况，有置信区间为

$S^2 = \frac{1}{n-1}\sum_{i=1}^{n}(X_i - \bar{X})^2$是$\sigma^2$的无偏估计量，则有

$$
\frac{(n-1)S^2}{\sigma^2} \sim \chi^2(n-1)
$$

对于给定的$\alpha$，有

$$
P\{\chi^2_{\alpha/2}(n-1) < \frac{(n-1)S^2}{\sigma^2} < \chi^2_{1-\alpha/2}(n-1)\} = 1-\alpha
$$

则有置信区间为

$$
(\frac{(n-1)S^2}{\chi^2_{\alpha/2}(n-1)},\frac{(n-1)S^2}{\chi^2_{1-\alpha/2}(n-1)})
$$

或

$$
(\frac{nS_0^2}{\chi^2_{\alpha/2}(n-1)},\frac{nS_0^2}{\chi^2_{1-\alpha/2}(n-1)})
$$

其中$S_0 = \sqrt{\frac{1}{n}\sum_{i=1}^{n}(X_i - \bar{X})^2}$

当$n$足够大时，根据中心极限定理，有 $ \frac{\bar{X}-\mu}{\alpha/\sqrt{n}} \sim N(0,1)$，则有置信区间为

$$
(\bar{X} - \frac{S_0}{\sqrt{n}}z_{\alpha/2},\bar{X} + \frac{S_0}{\sqrt{n}}z_{\alpha/2})
$$

|待估参数|其它参数|统计量|置信区间|
|:---:|:---:|:---:|:---:|
|$\mu$|$\sigma^2$已知|$T = \frac{\bar{X} - \mu}{\sigma/\sqrt{n}} \sim N(0,1)$|$$\left(\bar{X} - \frac{\sigma}{\sqrt{n}}z_{\alpha/2},\bar{X} + \frac{\sigma}{\sqrt{n}}z_{\alpha/2}\right)$$|
|$\mu$|$\sigma^2$未知|$T = \frac{\bar{X} - \mu}{S/\sqrt{n}} \sim t(n-1)$|$$\left(\bar{X} - \frac{S}{\sqrt{n}}t_{\alpha/2}(n-1),\bar{X} + \frac{S}{\sqrt{n}}t_{\alpha/2}(n-1)\right)$$|
|$\sigma^2$|$\mu$未知|$T = \frac{(n-1)S^2}{\sigma^2} \sim \chi^2(n-1)$|$$\left(\frac{(n-1)S^2}{\chi^2_{\alpha/2}(n-1)},\frac{(n-1)S^2}{\chi^2_{1-\alpha/2}(n-1)}\right)$$|



test


$$
D_z = \{(u,v) | u \geq v, v \leq z \}
$$

$$D_z = \{(u,v) | u \geq v, v \leq z \}$$

$D_z = \{(u,v) | u \geq v, v \leq z \}$

$D_z = \{(u,v) u \geq v, v \leq z \}$

$D_z = \{(u,v) u \geq v, v z \}$

$D_z = \{(u,v) u v, v z \}$

$D_z = (u,v) u v, v z $

$D_z = u,v u v, v z $

$D_z $