---
layout: post
title: 概率论公式整理
subtitle: 
categories: markdown Math
tags: [Math]
math: true
---

1. [概率](#概率)
2. [条件概率](#条件概率)
3. [独立性](#独立性)
   1. [伯努利实验](#伯努利实验)
4. [随机变量](#随机变量)
   1. [离散型随机变量](#离散型随机变量)
      1. [二项分布](#二项分布)
      2. [泊松分布](#泊松分布)
   2. [连续型随机变量](#连续型随机变量)
      1. [均匀分布](#均匀分布)
      2. [指数分布](#指数分布)
      3. [正态分布](#正态分布)
      4. [随机变量函数的分布](#随机变量函数的分布)
5. [随机向量](#随机向量)
   1. [分布律](#分布律)
   2. [边缘分布律](#边缘分布律)
   3. [条件分布](#条件分布)
   4. [二维随机变量函数的分布](#二维随机变量函数的分布)
      1. [1. $Z = X+Y$](#1-z--xy)
      2. [2. $Z = \\frac{X}{Y}$](#2-z--fracxy)
      3. [3. $Z = XY$](#3-z--xy)
      4. [4. $M = \\max{X,Y}$](#4-m--maxxy)
      5. [5. $N = \\min{X,Y}$](#5-n--minxy)
6. [数字特征](#数字特征)
   1. [期望](#期望)
   2. [方差](#方差)
   3. [协方差](#协方差)
   4. [相关系数](#相关系数)
   5. [常用分布性质表](#常用分布性质表)
7. [大数定理](#大数定理)
   1. [切比雪夫不等式](#切比雪夫不等式)
   2. [切比雪夫大数定理](#切比雪夫大数定理)
   3. [辛钦大数定理](#辛钦大数定理)
   4. [伯努利大数定理](#伯努利大数定理)
8. [中心极限定理](#中心极限定理)
   1. [林德贝格-勒维/独立同分布中心极限定理](#林德贝格-勒维独立同分布中心极限定理)
   2. [李雅普诺夫/独立不同分布中心极限定理](#李雅普诺夫独立不同分布中心极限定理)
   3. [拉普拉斯/局部极限定理 、棣莫弗-拉普拉斯/积分极限定理](#拉普拉斯局部极限定理-棣莫弗-拉普拉斯积分极限定理)
9. [随机样本](#随机样本)
   1. [统计量](#统计量)
   2. [重要统计量](#重要统计量)
      1. [1. 样本均值](#1-样本均值)
      2. [2. 样本方差](#2-样本方差)
      3. [3. 样本$k$阶原点矩](#3-样本k阶原点矩)
      4. [4. 样本$k$阶中心矩](#4-样本k阶中心矩)
10. [抽样分布](#抽样分布)
    1. [重要抽样分布](#重要抽样分布)
       1. [1. $\\chi^2$ 分布](#1-chi2-分布)
       2. [2. $t$ 分布](#2-t-分布)
       3. [3. $F$ 分布](#3-f-分布)
    2. [重要性质](#重要性质)
11. [参数估计](#参数估计)
    1. [矩估计](#矩估计)
    2. [最大似然估计(Maximum Likelihood Estimation)](#最大似然估计maximum-likelihood-estimation)
    3. [估计的评价标准](#估计的评价标准)
       1. [无偏性](#无偏性)
       2. [有效性](#有效性)
       3. [一致性](#一致性)
    4. [区间估计](#区间估计)
       1. [置信区间](#置信区间)
       2. [枢轴变量](#枢轴变量)
       3. [枢轴量法](#枢轴量法)
       4. [正态总体的区间估计](#正态总体的区间估计)
          1. [1. 对$\\mu$的估计](#1-对mu的估计)
          2. [2. 对$\\sigma^2$的估计](#2-对sigma2的估计)
12. [假设检验](#假设检验)
    1. [统计假设](#统计假设)
       1. [统计假设的形式](#统计假设的形式)
       2. [显著性水平、拒绝域、临界值](#显著性水平拒绝域临界值)
    2. [检验方法的两类错误](#检验方法的两类错误)
    3. [当个正态总体的假设检验](#当个正态总体的假设检验)


## 概率

频率 $f_n(A)=\frac{k}{n}$
1. $ 0 \leq f_n(A) \leq 1$
2. 对于必然事件$\Omega$ $f_n(\Omega)=1$
3. 若事件不相容 $A \cap B = \emptyset$ 则 $f_n(A \cup B) = f_n(A) + f_n(B)$

若事件两两不相容

$$
f_n(\bigcup_{i=1}^n A_i) = \sum_{i=1}^n f_n(A_i)
$$

有限可加性：事件$A_i$两两不相容

$$
P(\bigcup_{i=1}^{n} A_i) = \sum_{i=1}^{n} P(A_i)
$$

基本运算公式

$$
\begin{align*}
    P(A \cup B) &= P(A) + P(B) - P(A \cap B)\\
    P(A - B) &= P(A) - P(A \cap B)\\
    P( \overline{A} ) &= 1 - P(A)\\
    P(A \cup B \cup C) &= P(A) + P(B) + P(C) - P(A \cap B) - P(A \cap C) - P(B \cap C) + P(A \cap B \cap C)\\
    P(\bigcup_{i=1}^{n} A_i) &= \sum_{i=1}^{n} P(A_i) - \sum_{1 \leq i < j \leq n} P(A_i \cap A_j) + \sum_{1 \leq i < j < k \leq n} P(A_i \cap A_j \cap A_k) + \cdots + (-1)^{n-1} P(A_1 \cap A_2 \cap \cdots \cap A_n)
\end{align*}
$$

## 条件概率

**条件概率**
$$
P(B|A) = \frac{P(AB)}{P(A)}
$$

含义：在事件A发生的条件下，事件B发生的概率
变式
$$
\begin{align*}
P(AB) &= P(A)P(B|A) = P(B)P(A|B)\\
P(AB) &= \frac{P(AB|U)}{P(B|U)}\\
P(ABC) &= P(A)P(B|A)P(C|AB)\\
P(\bigcap_{i=1}^{n} A_i) &= P(A_1)P(A_2|A_1)P(A_3|A_1A_2) \cdots P(A_n|A_1A_2 \cdots A_{n-1})
\end{align*}
$$

**全概率公式**
$$
P(B) = \sum_{i=1}^{n} P(A_i)P(B|A_i)
$$

含义：B的概率等于在所有可能发生的事件$A_i$发生的条件下，B发生的概率的和
**贝叶斯公式（逆概率公式）**
$$
P(A_i|B) = \frac{P(A_i)P(B|A_i)}{\sum_{j=1}^{n} P(A_j)P(B|A_j)} = \frac{P(A_i)P(B|A_i)}{P(B)}
$$

## 独立性

$$
\begin{align*}
P(AB) &= P(A)P(B)\\
P(ABC) &= P(A)P(B)P(C)\\
P(\bigcap_{i=1}^{n} A_i) &= \prod_{i=1}^{n} P(A_i)
\end{align*}
$$

若A,B独立，则

$A \cap B = \emptyset$，
$P(A \cap B) = 0$，
$P(A \cup B) = P(A) + P(B)$, 
$P(B|A) = P(B|\overline{A}) P(B)$

### 伯努利实验
1. 试验只有两个结果：$A$和$\overline{A}$
2. 试验可以重复进行
3. 每次试验结果相互独立

$$
P(A)=p \qquad P(\overline{A})=1-p
$$

k重伯努利实验下A出现k次的概率

$$
P_n(k) = C_n^k p^k (1-p)^{n-k}
$$

## 随机变量
**随机变量**：对于随机试验，对每个样本点赋予一个实数，这个实数就是随机变量
**离散型随机变量**：随机变量只能取有限个或可列个值
**连续型随机变量**：随机变量的取值是一个区间内的任意一个值

**分布函数**
X是一个随机变量，对于任意实数x，函数

$$
F(x) = P\{X \leq x\}
$$

称为X的分布函数

1. $F(x)$非严格单调递增
2. $0 \leq F(x) \leq 1$
3. $\lim_{x \to -\infty} F(x) = 0$，$\lim_{x \to +\infty} F(x) = 1$
4. $F(x)$右连续（左闭右开）

### 离散型随机变量
概率分布、分布律

$$
P\{X=x_i\} = p_i \qquad i=1,2,\cdots
$$

1. $p_i \geq 0$
2. $\sum_{i=1}^{\infty} p_i = 1$

#### 二项分布
二项分布是n重伯努利实验中成功次数的离散型概率分布

$$
P\{X=k\} = C_n^k p^k (1-p)^{n-k} \qquad k=0,1,2,\cdots,n
$$

#### 泊松分布
泊松分布是二项分布的极限情况，当n很大，p很小时，二项分布近似于泊松分布

$$
P\{X=k\} = \lim_{n \to \infty} C_n^k p^k (1-p)^{n-k} = \frac{\lambda^k}{k!} e^{-\lambda} \qquad k=0,1,2,\cdots
$$

其中$\lambda = np$，是泊松分布的参数

泊松分布的期望和方差

$$
E(X) = \lambda \qquad D(X) = \lambda
$$

### 连续型随机变量
概率密度函数

$$
F(x) = \int_{-\infty}^{x} f(t) dt
$$

$$
\begin{align*}
f(x) &\geq 0\\
\int_{-\infty}^{+\infty} f(x) dx &= 1\\
P\{a \leq X \leq b\} &= \int_{a}^{b} f(x) dx\\
F^{'}(x) &= f(x) \qquad 如果f(x)在x处连续
\end{align*}
$$

#### 均匀分布

$$
f(x) = \begin{cases}
\frac{1}{b-a} & a \leq x \leq b\\
0 & 其他
\end{cases}
$$

$$
F(x) = \begin{cases}
0 & x < a\\
\frac{x-a}{b-a} & a \leq x \leq b\\
1 & x > b
\end{cases}
$$

均匀分布的期望和方差

$$
E(X) = \frac{a+b}{2} \qquad D(X) = \frac{(b-a)^2}{12}
$$

#### 指数分布

$$
f(x) = \begin{cases}
\lambda e^{-\lambda x} & x \geq 0\\
0 & x < 0
\end{cases}
$$

$$
F(x) = \begin{cases}
1-e^{-\lambda x} & x \geq 0\\
0 & x < 0
\end{cases}
$$

无记忆性

$$
P\{X > s+t | X > s\} = P\{X > t\}
$$

指数分布的期望和方差

$$
E(X) = \frac{1}{\lambda} \qquad D(X) = \frac{1}{\lambda^2}
$$

#### 正态分布

$$
f(x) = \frac{1}{\sigma\sqrt{2\pi}} e^{-\frac{(x-\mu)^2}{2\sigma^2}} =
\frac{1}{\sigma\sqrt{2\pi}} \exp({-\frac{(x-\mu)^2}{2\sigma^2}})
$$

正态分布的期望和方差

$$
E(X) = \mu \qquad D(X) = \sigma^2
$$

标准正态分布 $X \sim N(0,1)$

对于一般的正态分布$X \sim N(\mu,\sigma^2)$，可以通过标准化来转化为标准正态分布

$$
Z = \frac{X-\mu}{\sigma} \sim N(0,1)
$$

注意 $\sigma = \sqrt{D(X)}$

拓展：$e^{-x^2}$ 的积分为$\sqrt{\pi}$

在二维平面中，样本点的期望值为 $(0，0)$
样本的的分布遵循以下几个特性：

1. 距离对称性 $f(x,y) = f(r) = f(\sqrt{x^2+y^2})$
2. 独立性 $f(x,y) = g(x)h(y)$

$$
\begin{align*}
f(r,0) &= f(r) = g(r)h(0)\\
f(0,r) &= f(r) = g(0)h(r)\\
\text{assume }& g(0) = h(0) = 1\\
\text{then }& g(r) = h(r) = f(r)\\    
f(\sqrt{x^2+y^2}) &= f(x)f(y)\\
\text{construct }& h(x) = f(x^2)\\
h(x^2+y^2) &= h(x^2)h(y^2)\\
h(x+y) &= h(x)h(y)\\
\text{as }& x \in R\\
h(r) &= e^{cr}\\
f(r) &= e^{cr^2}
\end{align*}
$$

对$f(x,y)$积分，其结果应当为常数，改写$f(x) = e^{-cr^2}$我们在极坐标下对其积分

$$
\begin{align*}
\int_{0}^{\infty} \int_{0}^{2\pi}  f(r) r dr d\theta 
&= \int_{0}^{\infty} \int_{0}^{2\pi}  e^{-cr^2} r dr d\theta \\
&= \int_{0}^{\infty} e^{-cr^2} r dr \int_{0}^{2\pi} d\theta \\
&= \int_{0}^{\infty} e^{-cr^2} r dr \cdot 2\pi \\
&= \frac{\pi}{c}
\end{align*}
$$

再次回到$f(x,y)$，我们对其积分

$$
\begin{align*}
\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} f(x,y) dx dy
&= \int_{-\infty}^{\infty}f(x) dx\int_{-\infty}^{\infty} f(y) dy\\
&= (\int_{-\infty}^{\infty}f(x) dx)^2
\end{align*}
$$

在前我们已经得到了积分结果为$\frac{\pi}{c}$，所以

$$
\int_{-\infty}^{\infty}e^{-cx^2} dx = \sqrt{\frac{\pi}{c}}
$$

因为概率密度函数的积分结果为1，我们先令$c=1$，只要对函数$f(x)$进行变换，就可以得到正态分布的概率密度函数，具体来说这个变换为

$$
\varphi(x) = \frac{1}{\sqrt{\pi}}\frac{1}{\sqrt{2\sigma^2}} f(\frac{x-\mu}{\sqrt{2\sigma^2}})
$$

我们得到了最终的正态分布的概率密度函数

$$
\varphi(x) = \frac{1}{\sigma\sqrt{2\pi}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}
$$

#### 随机变量函数的分布
设X是一个随机变量，Y是随机变量X的函数，即$Y = g(X)$，则Y是一个随机变量，其分布函数为

$$
\begin{align*}
F_Y(y) &= P\{Y \leq y\}\\
&= P\{g(X) \leq y\}\\
&= P\{X \leq g^{-1}(y)\}\\
&= F_X(g^{-1}(y))\\
\end{align*}
$$

$$
f_Y(y) = \frac{dF_Y(y)}{dy} = f_X(g^{-1}(y)) |\frac{dg^{-1}(y)}{dy}|
$$

## 随机向量
**随机向量**：设$(X_1,X_2,\cdots,X_n)$是n个随机变量，它们构成的向量$(X_1,X_2,\cdots,X_n)$称为n维随机向量

**二维随机向量**：设$(X,Y)$是二维随机变量，对于任意实数$x,y$，函数

$$
F(x,y) = P\{X \leq x, Y \leq y\}
$$

称为二维随机变量$(X,Y)$的分布函数

1. $\frac{\partial F}{\partial x} \geq 0 \quad \frac{\partial F}{\partial y} \geq 0$
2. $0 \leq F(x,y) \leq 1$
3. $F(-\infty,y) = F(x,-\infty) = 0$
4. $F(+\infty,+\infty) = 1$
5. $F(x,y)$关于x和y都是右连续的
6. $P\{a_1 < X \leq b_1, a_2 < Y \leq b_2\} = F(b_1,b_2) - F(a_1,b_2) - F(b_1,a_2) + F(a_1,a_2)$

**二维离散型随机变量**：设$(X,Y)$是二维随机变量，如果存在一列非负常数$p_{ij}(i,j=1,2,\cdots)$，使得
$$
P\{X=x_i,Y=y_j\} = p_{ij} \qquad i,j=1,2,\cdots
$$

则称$(X,Y)$为二维离散型随机变量，其中$p_{ij}$满足

$$
\sum_{i=1}^{\infty} \sum_{j=1}^{\infty} p_{ij} = 1
$$

**二维连续型随机变量**：设$(X,Y)$是二维随机变量，如果存在非负常数$f(x,y)$，使得对于任意实数$x,y$，有

$$
P\{(X,Y) \in D\} = \iint_D f(x,y)dxdy
$$

### 分布律

二维离散型随机变量的分布律

$$
\begin{align*}
P\{X=x_i,Y=y_j\} &= p_{ij} \qquad i,j=1,2,\cdots\\
\end{align*}
$$

二维连续型随机变量的概率密度

$$
\begin{align*}
f(x,y) &\geq 0\\
\iint_{-\infty}^{+\infty} f(x,y)dxdy &= 1\\
\frac{\partial^2 F(x,y)}{\partial x \partial y} &= f(x,y) \quad 若f(x,y)在点(x,y)连续\\
P\{(X,Y) \in D\} &= \iint_D f(x,y)dxdy
\end{align*}
$$

### 边缘分布律
二维离散型随机变量的边缘分布律

$$
\begin{align*}
P\{X=x_i\} &= \sum_{j=1}^{\infty} P\{X=x_i,Y=y_j\} = \sum_{j=1}^{\infty} p_{ij} \qquad i=1,2,\cdots\\
P\{Y=y_j\} &= \sum_{i=1}^{\infty} P\{X=x_i,Y=y_j\} = \sum_{i=1}^{\infty} p_{ij} \qquad j=1,2,\cdots
\end{align*}
$$

二维连续型随机变量的边缘概率密度

$$
\begin{align*}
f_X(x) &= \int_{-\infty}^{+\infty} f(x,y)dy\\
f_Y(y) &= \int_{-\infty}^{+\infty} f(x,y)dx
\end{align*}
$$

二维连续型随机变量的边缘分布律

$$
\begin{align*}
F_X(x) &= P\{X \leq x\} = P\{X \leq x, -\infty < Y < +\infty\} = \int_{-\infty}^{x} \int_{-\infty}^{+\infty} f(u,y)dydu = \int_{-\infty}^{x} f_X(u)du\\
F_Y(y) &= P\{Y \leq y\} = P\{Y \leq y, -\infty < X < +\infty\} = \int_{-\infty}^{y} \int_{-\infty}^{+\infty} f(x,v)dxdv = \int_{-\infty}^{y} f_Y(v)dv
\end{align*}
$$

### 条件分布
条件分布

$$
\begin{align*}
F_{X|Y}(x|y) &= P\{X \leq x|Y=y\} = \frac{P\{X \leq x, Y=y\}}{P\{Y=y\}} = \frac{\int_{-\infty}^{x} f(u,y)du}{f_Y(y)}\\
f_{X|Y}(x|y) &= \frac{f(x,y)}{f_Y(y)}\\
F_{Y|X}(y|x) &= P\{Y \leq y|X=x\} = \frac{P\{X=x, Y \leq y\}}{P\{X=x\}} = \frac{\int_{-\infty}^{y} f(x,v)dv}{f_X(x)}\\
f_{Y|X}(y|x) &= \frac{f(x,y)}{f_X(x)}
\end{align*}
$$

二维离散型随机变量的条件分布律

$$
\begin{align*}
P\{X=x_i|Y=y_j\} &= \frac{P\{X=x_i,Y=y_j\}}{P\{Y=y_j\}} = \frac{p_{ij}}{\sum_{k=1}^{\infty} p_{kj}} \qquad i=1,2,\cdots\\
P\{Y=y_j|X=x_i\} &= \frac{P\{X=x_i,Y=y_j\}}{P\{X=x_i\}} = \frac{p_{ij}}{\sum_{k=1}^{\infty} p_{ik}} \qquad j=1,2,\cdots
\end{align*}
$$

### 二维随机变量函数的分布
设$(X,Y)$是二维随机变量，$Z=\varphi(X,Y)$是由$(X,Y)$所确定的随机变量，如果对于任意实数$z$，有

$$
P\{Z \leq z\} = P\{\varphi(X,Y) \leq z\} = P\{(X,Y) \in D_z\} = \iint_{D_z} f(x,y)dxdy
$$

#### 1. $Z = X+Y$

$$
\begin{align*}
    F_Z(z) = P\{X+Y \leq z\} 
    &= \iint_{x+y \leq z} f(x,y)dxdy\\
    &= \int_{-\infty}^{+\infty} dy\int_{-\infty}^{z-y} f(x,y)dx\\
\end{align*}
$$

令$u=x+y,v=y$，则 $x=u-v,y=v$，
$$
D_z = \{(u,v) | u \geq v, v \leq z \}
$$

$$
\begin{align*}
    F_Z(z) &= \int_{-\infty}^{+\infty} \int_{-\infty}^{z} f(u-v,v)du dv\\
    &= \int_{-\infty}^{z}  du \int_{-\infty}^{+\infty} f(u-v,v)dv\\
    &= \int_{-\infty}^{z} f_Z(u)du
\end{align*}
$$

由对称性可得

$$
\begin{align*}
f_Z(z) &= \int_{-\infty}^{+\infty} f(z-y,y)dy\\
&= \int_{-\infty}^{+\infty} f(x,z-x)dx\\
\end{align*}
$$

几何含义：$f_Z(z)$是$f(x,y)$在直线 $x+y=z$ 上的积分（将$f(x,y)$ 的 $x+y=z$ 映射到 $f_Z(z)$ 的 $z$点 ）

当$f(x,y) = f_X(x)f_Y(y)$时，$X,Y$相互独立，得到卷积公式

$$
\begin{align*}
f_Z(z) = f_X*f_Y&= \int_{-\infty}^{+\infty} f_X(x)f_Y(z-x)dx\\
&= \int_{-\infty}^{+\infty} f_X(z-y)f_Y(y)dy\\
\end{align*}
$$

若 $X,Y$相互独立 且服从 $N(\mu_1,\sigma_1^2),N(\mu_2,\sigma_2^2)$，则 $Z=X+Y$ 服从 $N(\mu_1+\mu_2,\sigma_1^2+\sigma_2^2)$

$$
\begin{align*}
f_Z(z) &= \int_{-\infty}^{+\infty} \frac{1}{\sqrt{2\pi}\sigma_1}e^{-\frac{(x-\mu_1)^2}{2\sigma_1^2}} \frac{1}{\sqrt{2\pi}\sigma_2}e^{-\frac{(z-x-\mu_2)^2}{2\sigma_2^2}}dx\\
& \cdots\\
&= \frac{1}{\sqrt{2\pi}\sqrt{\sigma_1^2+\sigma_2^2}}e^{-\frac{(z-\mu_1-\mu_2)^2}{2(\sigma_1^2+\sigma_2^2)}}
\end{align*}
$$

#### 2. $Z = \frac{X}{Y}$

$$
\begin{align*}
    F_Z(z) = P\{\frac{X}{Y} \leq z\} = \iint_{\frac{x}{y} \leq z} f(x,y)dxdy\\
\end{align*}
$$

令$u=y \qquad v=\frac{x}{y}$，则 $x=uv,y=u$，
$$
D_z = \{(u,v) | u \geq 0, v \leq z\}
$$

jacobian矩阵：原坐标系 $(x,y)$ 在新坐标系 $(u,v)$ 的微分元素面积为 $|J|dudv$ ，其中 $|J|$ 为jacobian矩阵的行列式

$$
J = \begin{vmatrix}
    \frac{\partial x}{\partial u} & \frac{\partial x}{\partial v}\\
    \frac{\partial y}{\partial u} & \frac{\partial y}{\partial v}\\
\end{vmatrix} = \begin{vmatrix}
    v & u\\
    1 & 0\\
\end{vmatrix} = -u
$$

$$
\begin{align*}
    F_Z(z) &= \int_{-\infty}^{+\infty} \int_{-\infty}^{z} f(uv,u)|J|du dv \\
    &= \int_{-\infty}^{z} \int_{0}^{+\infty} f(uv,u)|u|du dv\\
    &= \int_{-\infty}^{z} f_Z(v)dv
\end{align*}
$$

$$
\begin{align*}
f_Z(z) &= \int_{-\infty}^{+\infty} f(zu,u)|u|du\\
\end{align*}
$$

当$f(x,y) = f_X(x)f_Y(y)$时，$X,Y$相互独立

$$
f_Z(z) = \int_{-\infty}^{+\infty} f_X(zu)f_Y(u)|u|du
$$

#### 3. $Z = XY$ 

$$
\begin{align*}
    F_Z(z) = P\{XY \leq z\} = \iint_{xy \leq z} f(x,y)dxdy
\end{align*}
$$

令$u=y \qquad v=xy$，则 $x=\frac{v}{u},y=u$，

$$
J = \begin{vmatrix}
    \frac{\partial x}{\partial u} & \frac{\partial x}{\partial v}\\
    \frac{\partial y}{\partial u} & \frac{\partial y}{\partial v}\\
\end{vmatrix} = \begin{vmatrix}
    -\frac{v}{u^2} & \frac{1}{u}\\
    1 & 0\\
\end{vmatrix} = -\frac{1}{u}
$$

$$
\begin{align*}
    F_Z(z) &= \int_{-\infty}^{+\infty} \int_{-\infty}^{z} f(\frac{v}{u},u)|J|du dv \\
    &= \int_{-\infty}^{z} \int_{0}^{+\infty} f(\frac{v}{u},u)|\frac{1}{u}|du dv\\
    &= \int_{-\infty}^{z} f_Z(v)dv
\end{align*}
$$

$$
f_Z(z) = \int_{-\infty}^{+\infty} f(\frac{z}{u},u)|\frac{1}{u}|du
$$

#### 4. $M = \max\{X,Y\}$

X,Y相互独立

$$
\begin{align*}
    F_M(m) &= P\{\max\{X,Y\} \leq m\}\\
    &= P\{X \leq m\}P\{Y \leq m\}\\
    &= F_X(m)F_Y(m)
\end{align*}
$$

#### 5. $N = \min\{X,Y\}$

X,Y相互独立

$$
\begin{align*}
    F_N(n) &= P\{\min\{X,Y\} \leq n\}\\
    &= 1 - P\{\min\{X,Y\} > n\}\\
    &= 1 - P\{X > n\}P\{Y > n\}\\
    &= 1 - (1-F_X(n))(1-F_Y(n))\\
\end{align*}
$$

## 数字特征
### 期望
离散型随机变量的期望

$$
E(X) = \sum_{i=1}^{n} x_i p_i
$$

连续型随机变量的期望

$$
E(X) = \int_{-\infty}^{+\infty} xf(x)dx
$$

性质

$$
    E(Z) = E(g(X)) = \sum_{i=1}^{n} g(x_i)p_i \qquad E(Z) = E(g(X)) = \int_{-\infty}^{+\infty} g(x)f(x)dx\\
$$

$$
E(aX+bY) = aE(X) + bE(Y)\\
$$

若X,Y相互独立，则

$$
E(XY) = E(X)E(Y)
$$

### 方差
离散型随机变量的方差

$$
D(X) = \sum_{i=1}^{n} (x_i - E(X))^2 p_i = E(X^2) - [E(X)]^2
$$

连续型随机变量的方差

$$
D(X) = \int_{-\infty}^{+\infty} (x - E(X))^2 f(x)dx = E(X^2) - [E(X)]^2
$$

性质

$$
    D(aX+b) = a^2D(X)
$$

$$
\begin{align*}
    D(X \pm Y) &= D(X) + D(Y) \pm 2Cov(X,Y)\\
    &= D(X) + D(Y) \qquad X,Y相互独立\\
\end{align*}
$$

$$
    D(X) < E[(X-c)^2] \qquad c \neq E(X)
$$

$$
    D(X) = 0 \Leftrightarrow X = c \qquad c为常数
$$

### 协方差

$$
Cov(X,Y) = E[(X-E(X))(Y-E(Y))] = E(XY) - E(X)E(Y)
$$

性质

$$
\begin{align*}
    Cov(X,Y) &= Cov(Y,X)\\
    Cov(aX+bY,Z) &= aCov(X,Z) + bCov(Y,Z)\\
    Cov(X,Y) &= 0 \Leftarrow X,Y相互独立\\
\end{align*}
$$

### 相关系数

$$
\rho_{XY} = \frac{Cov(X,Y)}{\sqrt{D(X)D(Y)}} = \frac{E(XY) - E(X)E(Y)}{\sqrt{D(X)D(Y)}}
$$

性质

$$
\begin{align*}
    \rho_{XY} &= \rho_{YX}\\
    |\rho_{XY}| &\leq 1\\
    |\rho_{XY}| &= 1 \Leftrightarrow P\{Y=aX+b\} = 1\\
    \rho_{XY} &= 0 \Leftrightarrow X,Y相互独立
\end{align*}
$$

### 常用分布性质表
|—|
|:---:|

|分布|分布律（概率密度）|期望|方差|范围|
|:---:|:---:|:---:|:---:|:---:|
|0-1分布|$p\{X=1\} = p,p\{X=0\} = q$|$p$|$pq$|$0<p<1,q=1-p$|
|二项分布$X\sim b(n,p)$|$p\{X=k\} = C_n^kp^kq^{n-k}$|$np$|$npq$|$0<p<1,q=1-p,n \in N^*$|
|泊松分布$X\sim P(\lambda)$|$p\{X=k\} = \frac{\lambda^k}{k!}e^{-\lambda}$|$\lambda$|$\lambda$|$\lambda>0$|
|均匀分布$X\sim U(a,b)$|$f(x) = \begin{cases}\frac{1}{b-a},&a<x<b\newline 0,&其他\end{cases}$|$\frac{a+b}{2}$|$\frac{(b-a)^2}{12}$|$-\infty<a<b<+\infty$|
|指数分布$X\sim E(\lambda)$|$f(x) = \begin{cases}\lambda e^{-\lambda x},&x>0\newline 0,&x\leq 0\end{cases}$|$\frac{1}{\lambda}$|$\frac{1}{\lambda^2}$|$\lambda>0$|
|正态分布$X\sim N(\mu,\sigma^2)$|$f(x) = \frac{1}{\sqrt{2\pi}\sigma}\exp(-\frac{(x-\mu)^2}{2\sigma^2})$|$\mu$|$\sigma^2$|$-\infty<x<+\infty$|

## 大数定理

### 切比雪夫不等式

$$
P\{|X-E(X)| \geq \varepsilon\} \leq \frac{D(X)}{\varepsilon^2}
$$

$$
P\{|X-E(X)| < \varepsilon\} \geq 1 - \frac{D(X)}{\varepsilon^2}
$$

定义：**收敛**

设$Y_1,Y_2,\cdots,Y_n,\cdots$是随机变量序列，$a$是常数，如果对于任意的$\varepsilon > 0$，有

$$
\lim_{n \to \infty} P\{|Y_n - a| < \varepsilon\} = 1
$$

则称随机变量序列$Y_1,Y_2,\cdots,Y_n,\cdots$依概率收敛于$a$，记作

$$
Y_n \xrightarrow{P} a \qquad (n \to \infty)
$$

### 切比雪夫大数定理
条件
1. $X_1,X_2,\cdots,X_n,\cdots$相互独立
2. $\forall i \quad D(X_i) = \sigma^2 < l$ , $l$是常数
   
$$
\lim_{n \to \infty} P\{ |\frac{1}{n}\sum_{i=1}^{n}X_i - \frac{1}{n}\sum_{i=1}^{n}E(X_i)| < \varepsilon \} =1
$$

即

$$
\overline{X} \xrightarrow{P} \overline{E(X)} \qquad (n \to \infty)
$$

推论
当
1. $X_1,X_2,\cdots,X_n,\cdots$相互独立
2. $\forall i \quad E(X_i) = \mu \quad D(X_i) = \sigma^2$
   
$$
\lim_{n \to \infty} P\{|\frac{1}{n}\sum_{i=1}^{n}X_i - \mu| < \varepsilon\} = 1
$$

即

$$
\overline{X} \xrightarrow{P} \mu \qquad (n \to \infty)
$$



### 辛钦大数定理

条件
1. $X_1,X_2,\cdots,X_n,\cdots$相互独立
2. $X_i$服从同一分布
3. $E(X_i) = \mu$
   
$$
\lim_{n \to \infty} P\{|\frac{1}{n}\sum_{i=1}^{n}X_i - \mu| < \varepsilon\} = 1
$$

即

$$
\overline{X} \xrightarrow{P} \mu \qquad (n \to \infty)
$$

### 伯努利大数定理
$n_A$是$n$次重实验中时间A发生的次数，A发生的概率为$p$

$$
\lim_{n \to \infty} P\{|\frac{n_A}{n} - p| < \varepsilon\} = 1
$$

即

$$
\frac{n_A}{n} \xrightarrow{P} p \qquad (n \to \infty)
$$

## 中心极限定理

### 林德贝格-勒维/独立同分布中心极限定理
条件
1. $X_1,X_2,\cdots,X_n,\cdots$相互独立
2. $X_i$服从同一分布，$E(X_i) = \mu \quad D(X_i) = \sigma^2$

$$
\lim_{n \to \infty} P\{\frac{\sum_{i=1}^{n}X_i - n\mu}{\sigma\sqrt{n}} \leq x\} = \frac{1}{\sqrt{2\pi}}\int_{-\infty}^{x}e^{-\frac{t^2}{2}}dt
$$

即当$n$充分大时

$$
\begin{align*}
\frac{\sum_{i=1}^{n}X_i - n\mu}{\sigma\sqrt{n}} \sim N(0,1)\\
\sum_{i=1}^{n}X_i \sim N(n\mu,n\sigma^2)
\end{align*}
$$

相关性质： $X_1+X_2 \sim N(\mu_1+\mu_2,\sigma_1^2+\sigma_2^2)$

### 李雅普诺夫/独立不同分布中心极限定理
条件
1. $X_1,X_2,\cdots,X_n,\cdots$相互独立
2. $E(x_i) = \mu_i \quad D(X_i) = \sigma_i^2 \neq 0$

存在正数$\delta$使得当$n \to \infty$时

$$
\frac{1}{\sum_{i=1}^{n}\sigma_i^{2+\delta}}\sum_{i=1}^{n}E(|X_i - \mu_i|^{2+\delta}) \to 0
$$

则随机变量

$$
Z_n = \frac{\sum_{i=1}^{n}X_i - \sum_{i=1}^{n}\mu_i}{\sqrt{D(\sum_{i=1}^{n}X_i)}} = \frac{\sum_{i=1}^{n}X_i - \sum_{i=1}^{n}\mu_i}{\sqrt{\sum_{i=1}^{n}\sigma_i^2}}
$$

的分布函数$F_n(x)$对于任意$x$满足

$$
\lim_{n \to \infty} F_n(x) = \Phi(x)
$$

即当$n$充分大时

$$
\begin{align*}
Z_n &\sim N(0,1)\\
\sum_{i=1}^{n}X_i &\sim N(\sum_{i=1}^{n}\mu_i,\sum_{i=1}^{n}\sigma_i^2)
\end{align*}
$$

### 拉普拉斯/局部极限定理 、棣莫弗-拉普拉斯/积分极限定理
条件
1. 随机变量$X \sim B(n,p)$
2. $n$充分大

注：$E(X) = np\quad D(X) = npq \quad \sigma = \sqrt{npq}$
拉普拉斯定理

$$
P\{X=k\} \approx \frac{1}{\sqrt{2\pi npq}}e^{-\frac{(k-np)^2}{2npq}} = \frac{1}{\sqrt{npq}} \varphi(\frac{k-np}{\sqrt{npq}})
$$

棣莫弗-拉普拉斯

$$
\lim_{n \to \infty} P\{a \leq \frac{X-np}{\sqrt{npq}} \leq b\} = \Phi(b) - \Phi(a)
$$

即

$$
\begin{align*}
\frac{X-np}{\sqrt{npq}} &\sim N(0,1)\\
X &\sim N(np,npq)
\end{align*}
$$

## 随机样本

设$X_1,X_2,\cdots,X_n$是来自同一总体的$n$个相互独立的随机变量，称$X_1,X_2,\cdots,X_n$为一个容量为$n$的**简单随机样本**，简称**样本**。

若$X$的分布函数为$F(x)$，则$X_1,X_2,\cdots,X_n$的联合分布函数为

$$
F(x_1,x_2,\cdots,x_n) = \prod_{i=1}^{n}F(x_i)
$$

若$X$的概率密度为$f(x)$，则$X_1,X_2,\cdots,X_n$的联合概率密度为

$$
f(x_1,x_2,\cdots,x_n) = \prod_{i=1}^{n}f(x_i)
$$

### 统计量

设$X_1,X_2,\cdots,X_n$是来自总体$X$的一个样本，$g(X_1,X_2,\cdots,X_n)$是样本的一个函数，不含未知参数，则称$g(X_1,X_2,\cdots,X_n)$为**统计量**。

### 重要统计量

#### 1. 样本均值

$$
\overline{X} = \frac{1}{n}\sum_{i=1}^{n}X_i
$$

#### 2. 样本方差

$$
S^2 = \frac{1}{n-1}\sum_{i=1}^{n}(X_i - \overline{X})^2 = \frac{1}{n-1}(\sum_{i=1}^{n}X_i^2 - n\overline{X}^2)
$$

证明：

$$
\begin{align*}
E(\sum_{i=1}^{n}(X_i - \overline{X})^2) 
&= E(\sum_{i=1}^{n}(X_i^2 - 2X_i\overline{X} + \overline{X}^2))\\
&= E(\sum_{i=1}^{n}X_i^2 - 2\overline{X}\sum_{i=1}^{n}X_i + \sum_{i=1}^{n}\overline{X}^2)\\
&= E(\sum_{i=1}^{n}X_i^2 - 2n\overline{X}^2 + n\overline{X}^2)\\
&= E(\sum_{i=1}^{n}X_i^2 - n\overline{X}^2)\\
&= \sum_{i=1}^{n}E(X_i^2) - nE(\overline{X}^2)\\
&= \sum_{i=1}^{n}(D(X_i) + E(X_i)^2) - n(D(\overline{X}) + E(\overline{X})^2)\\
&= \sum_{i=1}^{n}(\sigma^2 + \mu^2) - n(\frac{\sigma^2}{n} + \mu^2)\\
&= n\sigma^2 + n\mu^2 - \sigma^2 - n\mu^2\\
&= (n-1)\sigma^2
\end{align*}
$$

其中

$$
D(\overline{X}) = D(\frac{1}{n}\sum_{i=1}^{n}X_i) = \frac{1}{n^2}D(\sum_{i=1}^{n}X_i) = \frac{1}{n^2}\sum_{i=1}^{n}D(X_i) = \frac{\sigma^2}{n}
$$

#### 3. 样本$k$阶原点矩

$$
A_k = \frac{1}{n}\sum_{i=1}^{n}X_i^k
$$

#### 4. 样本$k$阶中心矩

$$
B_k = \frac{1}{n}\sum_{i=1}^{n}(X_i - \overline{X})^k
$$

## 抽样分布

设$X_1,X_2,\cdots,X_n$是来自总体$X$的一个样本，$g(X_1,X_2,\cdots,X_n)$是样本的一个函数，不含未知参数，则$g(X_1,X_2,\cdots,X_n)$的分布称为**抽样分布**。

### 重要抽样分布

#### 1. $\chi^2$ 分布

设$X_1,X_2,\cdots,X_n$是来自$N(0,1)$的样本，则称随机变量

$$
\chi^2 = X_1^2 + X_2^2 + \cdots + X_n^2
$$

服从自由度为$n$的$\chi^2$分布，记为$\chi^2 \sim \chi^2(n)$

性质
1. $\chi^2_1 \sim \chi^2(n_1) \quad \chi^2_2 \sim \chi^2(n_2)$，且$\chi^2_1$与$\chi^2_2$相互独立，则$\chi^2_1 + \chi^2_2 \sim \chi^2(n_1 + n_2)$
2. $\chi^2 \sim \chi^2(n)$，则$E(\chi^2) = n$，$D(\chi^2) = 2n$

上分位数 $\chi_\alpha^2(n)$

$$
P\{\chi^2 \geq \chi_\alpha^2(n)\} = \alpha
$$

一般当 $n$ 充分大时($n>45$)，$\chi^2$分布近似得有

$$
\chi_\alpha^2(n) \approx \frac{1}{2} (z_\alpha + \sqrt{2n-1})^2 
$$

$z_\alpha$为标准正态分布的上$\alpha$分位数

$$
z_\alpha = \Phi^{-1}(1-\alpha)
$$

#### 2. $t$ 分布

设$X \sim N(0,1)$，$Y \sim \chi^2(n)$，且$X$与$Y$相互独立，则称随机变量

$$
t = \frac{X}{\sqrt{Y/n}}
$$

服从自由度为$n$的$t$分布，记为$t \sim t(n)$

上分位数 $t_\alpha(n)$

$$
P\{t \geq t_\alpha(n)\} = \alpha
$$

$t_\alpha(n)$具有对称性，即

$$
t_\alpha(n) = -t_{1-\alpha}(n)
$$

当 $n$ 充分大时($n>45$)，$t$分布近似得有

$$
t_\alpha(n) \approx z_\alpha
$$

#### 3. $F$ 分布

设$X \sim \chi^2(n_1)$，$Y \sim \chi^2(n_2)$，且$X$与$Y$相互独立，则称随机变量

$$
F = \frac{X/n_1}{Y/n_2}
$$

服从自由度为$(n_1,n_2)$的$F$分布，记为$F \sim F(n_1,n_2)$

$$
F_\alpha(n_1,n_2) = \frac{1}{F_{1-\alpha}(n_2,n_1)}
$$

### 重要性质

设 $X_1,X_2,\cdots,X_n$ 是总体 $N(\mu,\sigma^2)$ 的一个样本，$\overline{X}$和$S^2$分别是样本均值和样本方差，则有

$$
\overline{X} \sim N(\mu,\frac{\sigma^2}{n})
$$

$$
\frac{(n-1)S^2}{\sigma^2} \sim \chi^2(n-1)
$$

$$
\overline{X}与S^2相互独立
$$

$$
\frac{\overline{X} - \mu}{S/\sqrt{n}} \sim t(n-1)
$$

设 $X_1,x_2,\cdots,X_n$ 和 $Y_1,Y_2,\cdots,Y_m$ 分别是来自正态总体 $N(\mu_1,\sigma_1^2)$ 和 $N(\mu_2,\sigma_2^2)$ 的两个独立的样本，则有

$$
\frac{\overline{X} - \overline{Y} - (\mu_1 - \mu_2)}{S_\omega \sqrt{\frac{1}{n} + \frac{1}{m}}} \sim t(n+m-2)
$$

$$
S_\omega^2 = \frac{(n-1)S_X^2 + (m-1)S_Y^2}{n+m-2}
$$

## 参数估计

### 矩估计

**矩**：$k$阶原点矩$E(X^k)$，$k$阶中心矩$E(X-\mu)^k$

1. $E(X) = \mu$
2. $E(X^2) = \mu^2 + \sigma^2$
3. $E(X^3) = \mu^3 + 3\mu\sigma^2$
4. $E(X^4) = \mu^4 + 6\mu^2\sigma^2 + 3\sigma^4$

### 最大似然估计(Maximum Likelihood Estimation)

**Likelihood Function**

Likelihood Function是一个关于参数$\theta$的函数，表示在给定参数$\theta$的条件下，样本观测值出现的概率，记为$L(\theta)$

**Maximum Likelihood Estimation**

Maximum Likelihood Estimation是指在所有可能的参数值中，使得观测值出现的概率最大的那个参数值，记为$\hat{\theta}$

随机变量，$X$在参数 $\theta$ 西的概率分布为 $P\{X=x_i\} = f(x_i;\theta) \quad i=1,2,\cdots,n$ ，则样本$X_1,X_2,\cdots,X_n$的联合概率分布为

$$
P\{X_1=x_{i1},X_2=x_{i2},\cdots,X_n=x_{in}\} = \prod_{i=1}^{n}f(x_{i};\theta)
$$

其中$n_i$表示样本中$X$取值为$x_i$的个数，$n = \sum_{i=1}^{n}n_i$ ，则样本的 Likelihood Function 为

$$
L(p_1,p_2,\cdots,p_n) = \prod_{i=1}^{n}f(x_{i};\theta)
$$

找到使得 Likelihood Function 最大的参数值，即为 Maximum Likelihood Estimation

$$
\hat{\theta} = \arg \max_{\theta} L(\theta)
$$

因为 Likelihood Function 是连乘，求导不方便，通常对 Likelihood Function 函数取对数

$$
\ln L(\theta) = \sum_{i=1}^{n}\ln f(x_i;\theta)
$$

$$
\hat{\theta} = \arg \max_{\theta} \ln L(\theta)
$$

求 Likelihood Function 的最大值，即求对 Likelihood Function 的导数为0的点

$$
\frac{\partial \ln L(\theta)}{\partial \theta} = 0
$$

对于k个参数，有k个方程，解方程组得到参数的最大似然估计值

$$
\begin{cases}
\frac{\partial \ln L(\theta)}{\partial \theta_1} = 0\\
\frac{\partial \ln L(\theta)}{\partial \theta_2} = 0\\
\cdots\\
\frac{\partial \ln L(\theta)}{\partial \theta_k} = 0
\end{cases}
$$

### 估计的评价标准

#### 无偏性

**无偏性**：估计量的数学期望等于被估计参数的真实值

$$
E(\hat{\theta}) = \theta
$$

**无偏估计** $\hat{\theta}$ 的数学期望为 $\theta$

#### 有效性

**有效性**：估计量的方差小于等于其他估计量的方差

$$
D(\hat{\theta}) \leq D(\tilde{\theta})
$$

称$\hat{\theta}$比$\tilde{\theta}$有效

#### 一致性

**一致性**：当样本容量$n$趋于无穷大时，估计量的值趋于被估计参数的真实值

$$
\lim_{n \to \infty} \hat{\theta} = \theta
$$

或

$$
\lim_{n \to \infty} P\{|\hat{\theta} - \theta| < \epsilon\} = 1
$$


### 区间估计

#### 置信区间

**置信区间**：在一定置信水平下，估计参数的区间

设总体$X$的分布为$f(x;\theta)$，$\theta$为待估参数，$X_1,X_2,\cdots,X_n$为来自$X$的样本，$\hat{\theta}$为$\theta$的估计量，$\theta$的置信水平为$1-\alpha$，则称随机区间 $(\hat{\theta}_1,\hat{\theta}_2)$ 为$\theta$的置信水平为$1-\alpha$的置信区间，如果对于任意$\theta$，有

$$
P\{\hat{\theta}_1 < \theta < \hat{\theta}_2\} = 1-\alpha
$$

其中$\hat{\theta}_1,\hat{\theta}_2$为$\theta$的函数，称为置信下限和置信上限

#### 枢轴变量

**枢轴变量**：枢轴变量是样本均值$\overline{X}$和样本方差$S^2$的函数，记为$Q(\overline{X},S^2)$，枢轴变量的分布不依赖于待估参数，即枢轴变量的分布不依赖于$\theta$，则称$Q(\overline{X},S^2)$为$\theta$的枢轴量

#### 枢轴量法

**枢轴量法**：设总体$X$的分布为$f(x;\theta)$，$\theta$为待估参数，$X_1,X_2,\cdots,X_n$为来自$X$的样本，$\hat{\theta}$为$\theta$的估计量，$\theta$的置信水平为$1-\alpha$，$Q(\overline{X},S^2)$为$\theta$的枢轴量，$Q(\overline{X},S^2)$的分布不依赖于$\theta$，则有

$$
P\{a < Q(\overline{X},S^2) < b\} = 1-\alpha
$$

其中$a,b$为常数，由此得到$\theta$的置信水平为$1-\alpha$的置信区间为 $(\hat{\theta}_1,\hat{\theta}_2)$

#### 正态总体的区间估计

设总体$X$的分布为$N(\mu,\sigma^2)$，$\mu$为待估参数，$X_1,X_2,\cdots,X_n$为来自$X$的样本，$\overline{X}$为$\mu$的估计量，$S^2$为$\sigma^2$的估计量，$\mu$的置信水平为$1-\alpha$

##### 1. 对$\mu$的估计

**若$\sigma^2$已知**

$\sum_{i=1}^{n}X_i \sim N(n\mu,n\sigma^2)$ ，得到$\overline{X} \sim N(\mu,\frac{\sigma^2}{n})$

则有置信区间为

$$
(\overline{X} - \frac{\sigma}{\sqrt{n}}z_{\alpha/2},\overline{X} + \frac{\sigma}{\sqrt{n}}z_{\alpha/2})
$$

相关性质：$X_1+X_2 \sim N(\mu_1+\mu_2,\sigma_1^2+\sigma_2^2) \qquad kX \sim N(k\mu,k^2\sigma^2)$

**若$\sigma^2$未知**

考虑$S^2 = \frac{1}{n-1}\sum_{i=1}^{n}(X_i - \overline{X})^2$是$\sigma^2$的无偏估计量，则有

$$
\begin{align*}
\frac{\overline{X} - \mu}{\sigma/\sqrt{n}} &\sim N(0,1) \\
\frac{(n-1)S^2}{\sigma^2} &\sim \chi^2(n-1) \\
\frac{\overline{X} - \mu}{S/\sqrt{n}}=
 \frac{\overline{X} - \mu}{\sqrt{\sigma^2/n}} \cdot \frac{1}{\sqrt{\frac{(n-1)S^2}{\sigma^2}/(n-1)}} 
 &\sim t(n-1)
\end{align*}
$$

其中的$\frac{(n-1)S^2}{\sigma^2} \sim \chi^2(n-1)$会在下文中解释

$$
T = \frac{\overline{X} - \mu}{S/\sqrt{n}} \sim t(n-1)
$$

则有置信区间为

$$
(\overline{X} - \frac{S}{\sqrt{n}}t_{\alpha/2}(n-1),\overline{X} + \frac{S}{\sqrt{n}}t_{\alpha/2}(n-1))
$$

又因为 $\frac{S}{\sqrt{n}} = \frac{S_0}{\sqrt{n-1}}$ 其中$S_0 = \sqrt{\frac{1}{n}\sum_{i=1}^{n}(X_i - \overline{X})^2}$，置信区间可以写做

$$
(\overline{X} - \frac{S_0}{\sqrt{n-1}}t_{\alpha/2}(n-1),\overline{X} + \frac{S_0}{\sqrt{n-1}}t_{\alpha/2}(n-1))
$$

##### 2. 对$\sigma^2$的估计

只考虑$\mu$未知的情况

考虑$S^2 = \frac{1}{n-1}\sum_{i=1}^{n}(X_i - \overline{X})^2$是$\sigma^2$的无偏估计量，则有

$$
\frac{(n-1)S^2}{\sigma^2} \sim \chi^2(n-1)
$$

这里解释一下为什么是$\chi^2(n-1)$分布

$$
\begin{align*}
\frac{(n-1)S^2}{\sigma^2} &= \frac{\sum_{i=1}^{n}(X_i - \overline{X})^2}{\sigma^2} \\
&= \sum_{i=1}^{n}(\frac{(X_i - \mu) - (\overline{X}-\mu)}{\sigma})^2 \\
X_i - \mu &\sim N(0,\sigma^2) \\
\overline{X}-\mu &\sim N(0,\frac{\sigma^2}{n}) \\
(X_i - \mu) - (\overline{X}-\mu) &\sim N(0,\frac{n-1}{n}\sigma^2) \\
\frac{X_i - \overline{X}}{\sigma\sqrt{\frac{n-1}{n}}} &\sim N(0,1) \\
(\frac{X_i - \overline{X}}{\sigma\sqrt{\frac{n-1}{n}}})^2 &\sim \chi^2(1) \\
\frac{n}{n-1}\frac{(X_i - \overline{X})^2}{\sigma^2} &\sim \chi^2(1) \\
\frac{n}{n-1} \sum_{i=1}^{n}\frac{(X_i - \overline{X})^2}{\sigma^2} &\sim \chi^2(n) \\
\sum_{i=1}^{n}\frac{(X_i - \overline{X})^2}{\sigma^2} &\sim \frac{n-1}{n}\chi^2(n)  = \chi^2(n-1) \\
\end{align*}
$$


对于给定的$\alpha$，有

$$
P\{\chi^2_{\alpha/2}(n-1) < \frac{(n-1)S^2}{\sigma^2} < \chi^2_{1-\alpha/2}(n-1)\} = 1-\alpha
$$

注：$\alpha/2$ 指将概率(面积)分为两部分，$\alpha/2$在左边，$\alpha/2$ 在右边，$1-\alpha/2$指除去左侧$\alpha/2$的部分，剩下的右侧部分

则有置信区间为

$$
(\frac{(n-1)S^2}{\chi^2_{\alpha/2}(n-1)},\frac{(n-1)S^2}{\chi^2_{1-\alpha/2}(n-1)})
$$

或

$$
(\frac{nS_0^2}{\chi^2_{\alpha/2}(n-1)},\frac{nS_0^2}{\chi^2_{1-\alpha/2}(n-1)})
$$

其中$S_0 = \sqrt{\frac{1}{n}\sum_{i=1}^{n}(X_i - \overline{X})^2}$

当$n$足够大时，根据中心极限定理，有 $ \frac{\overline{X}-\mu}{\alpha/\sqrt{n}} \sim N(0,1)$，则有置信区间为

$$
(\overline{X} - \frac{S_0}{\sqrt{n}}z_{\alpha/2},\overline{X} + \frac{S_0}{\sqrt{n}}z_{\alpha/2})
$$

|待估参数|其它参数|统计量|置信区间|
|:---:|:---:|:---:|:---:|
|$\mu$|$\sigma^2$已知|$T = \frac{\overline{X} - \mu}{\sigma/\sqrt{n}} \sim N(0,1)$|$$\left(\overline{X} - \frac{\sigma}{\sqrt{n}}z_{\alpha/2},\overline{X} + \frac{\sigma}{\sqrt{n}}z_{\alpha/2}\right)$$|
|$\mu$|$\sigma^2$未知|$T = \frac{\overline{X} - \mu}{S/\sqrt{n}} \sim t(n-1)$|$$\left(\overline{X} - \frac{S}{\sqrt{n}}t_{\alpha/2}(n-1),\overline{X} + \frac{S}{\sqrt{n}}t_{\alpha/2}(n-1)\right)$$|
|$\sigma^2$|$\mu$未知|$T = \frac{(n-1)S^2}{\sigma^2} \sim \chi^2(n-1)$|$$\left(\frac{(n-1)S^2}{\chi^2_{\alpha/2}(n-1)},\frac{(n-1)S^2}{\chi^2_{1-\alpha/2}(n-1)}\right)$$|


## 假设检验

### 统计假设

关于总体 $X$ 的分布的假设称为统计假设，记为 $H$

1. 对于总体 $X$ 的分布的假设，称为**原假设**，记为 $H_0$
2. 对于总体 $X$ 的分布的假设，称为**备择假设**，记为 $H_1$
3. 原假设和备择假设是互斥的，即 $H_0$ 和 $H_1$ 不可能同时成立

#### 统计假设的形式

1. $H_0: \theta = \theta_0$，$H_1: \theta \neq \theta_0$
2. $H_0: \theta \leq \theta_0$，$H_1: \theta > \theta_0$
3. $H_0: \theta \geq \theta_0$，$H_1: \theta < \theta_0$
   
#### 显著性水平、拒绝域、临界值
1. 检验的显著水平是指在原假设为真时，拒绝原假设的概率，记为 $\alpha$
2. 检验的显著水平越小，说明检验的标准越高，检验的结论越可靠
3. 通常取 $\alpha = 0.05$ 或 $\alpha = 0.01$

在假设 $H_0$ 成立的条件下，构造统计量 $U$ ，给定**显著性水平** $\alpha$，使得**拒绝域** $W = \{|U| > \lambda_\alpha \}$ 的概率为 $\alpha$，则称 $\lambda_\alpha$ 为显著性水平为 $\alpha$ 的**临界值**，即

$$
P\{|U| > \lambda_\alpha \} = \alpha
$$

### 检验方法的两类错误

1. 第一类错误：原假设为真，但是被拒绝
   
    $$
    P\{拒绝H_0|H_0\text{为真}\} = \alpha
    $$

2. 第二类错误：原假设为假，但是被接受
   
    $$
    P\{接受H_0|H_0\text{为假}\} = \beta
    $$

### 当个正态总体的假设检验

**双边检测**：$H_0: \mu = \mu_0$，$H_1: \mu \neq \mu_0$

**单边检测**：$H_0: \mu \leq \mu_0$，$H_1: \mu > \mu_0$



|检验参数|条件|$H_0$|$H_1$|$H_0$的拒绝域|统计量|自由度|分位点|
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
|$\mu$|$\sigma^2$已知|$$\begin{array}{} \mu = \mu_0\\\mu \leq \mu_0\\\mu \geq \mu_0\end{array}$$|$$\begin{array}{} \mu \neq \mu_0\\\mu > \mu_0\\\mu < \mu_0\end{array}$$|$$\begin{array}{}\|Z\| >z_{\alpha/2}\\Z > z_{\alpha}\\Z < -z_{\alpha}\end{array}$$|$$Z = \frac{\overline{X} - \mu_0}{\sigma/\sqrt{n}} \sim N(0,1)$$|$\infty$|$$\begin{array}{}\pm z_{\alpha/2}\\ z_{\alpha/2}\\ -z_{\alpha/2}\end{array}$$|
|$\mu$|$\sigma^2$未知|$$\begin{array}{} \mu = \mu_0\\\mu \leq \mu_0\\\mu \geq \mu_0\end{array}$$|$$\begin{array}{} \mu \neq \mu_0\\\mu > \mu_0\\\mu < \mu_0\end{array}$$|$$\begin{array}{}\|T\| >t_{\alpha/2}\\T > t_{\alpha}\\T < -t_{\alpha}\end{array}$$|$$T = \frac{\overline{X} - \mu_0}{S/\sqrt{n}} \sim t(n-1)$$|$n-1$|$$\begin{array}{}\pm t_{\alpha/2}\\ t_{\alpha/2}\\ -t_{\alpha/2}\end{array}$$|
|$\sigma^2$|$\mu$未知|$$\begin{array}{} \sigma^2 = \sigma_0^2\\\sigma^2 \leq \sigma_0^2\\\sigma^2 \geq \sigma_0^2\end{array}$$|$$\begin{array}{} \sigma^2 \neq \sigma_0^2\\\sigma^2 > \sigma_0^2\\\sigma^2 < \sigma_0^2\end{array}$$|$$\begin{array}{}\chi^2 > \chi^2_{\alpha/2} \text{ and } \chi^2 < \chi^2_{1-\alpha/2} \\\chi^2 >\chi^2_{\alpha} \\\chi^2 < \chi^2_{1-\alpha}\end{array}$$|$$\chi^2 = \frac{(n-1)S^2}{\sigma_0^2} \sim \chi^2(n-1)$$|$n-1$|$$\begin{array}{}\chi^2_{\alpha/2},\chi^2_{1-\alpha/2}\\\chi^2_{\alpha}\\\chi^2_{1-\alpha}\end{array}$$|
|$\sigma^2$|$\mu$已知|$$\begin{array}{} \sigma^2 = \sigma_0^2\\\sigma^2 \leq \sigma_0^2\\\sigma^2 \geq \sigma_0^2\end{array}$$|$$\begin{array}{} \sigma^2 \neq \sigma_0^2\\\sigma^2 > \sigma_0^2\\\sigma^2 < \sigma_0^2\end{array}$$|$$\begin{array}{}\chi^2 > \chi^2_{\alpha/2} \text{ and } \chi^2 < \chi^2_{1-\alpha/2} \\\chi^2 >\chi^2_{\alpha} \\\chi^2 < \chi^2_{1-\alpha}\end{array}$$|$$\chi^2 = \frac{\sum_{i=1}^n(X_i - \mu_0)^2}{\sigma_0^2} \sim \chi^2(n)$$|$n$|$$\begin{array}{}\chi^2_{\alpha/2},\chi^2_{1-\alpha/2}\\\chi^2_{\alpha}\\\chi^2_{1-\alpha}\end{array}$$|









